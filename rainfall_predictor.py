# -*- coding: utf-8 -*-
"""Rainfall Predictor

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rHJGyp1GvrGmSKWUeT2tQKLU8KVYG1ez
"""

import seaborn as sns
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from sklearn.utils import resample
from sklearn.model_selection import train_test_split, cross_val_score,GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
import pickle

rainfall_data = pd.read_csv("/content/train.csv")
print(type(rainfall_data))

rainfall_data.shape

rainfall_data.head()

rainfall_data["day"].unique()

rainfall_data.info()

rainfall_data.columns

rainfall_data = rainfall_data.drop(columns=["day"])

rainfall_data.columns

print(rainfall_data.isnull().sum())

rainfall_data["rainfall"].unique()

rainfall_data.shape

rainfall_data.columns

sns.set(style="whitegrid")

rainfall_data.describe()

plt.figure(figsize=(20,15))
for i,column in enumerate(['id', 'pressure', 'maxtemp', 'temparature', 'mintemp', 'dewpoint',
       'humidity', 'cloud', 'sunshine', 'winddirection', 'windspeed',
       'rainfall'],1):
  plt.subplot(4,3,i)
  sns.histplot(rainfall_data[column],kde=True)
plt.tight_layout()
plt.show()

plt.figure(figsize=(6,4))
sns.countplot(x="rainfall",data=rainfall_data)
plt.title=("Rainfall Dist.")
plt.show()

plt.figure(figsize=(10,8))
sns.heatmap(rainfall_data.corr(),annot=True,cmap="coolwarm",fmt=".2f")
plt.show()

plt.figure(figsize=(20,15))
for i,column in enumerate(['id', 'pressure', 'maxtemp', 'temparature', 'mintemp', 'dewpoint',
       'humidity', 'cloud', 'sunshine', 'winddirection', 'windspeed',
       'rainfall'],1):
  plt.subplot(4,3,i)
  sns.boxplot(rainfall_data[column])
plt.tight_layout()
plt.show()

rainfall_data = rainfall_data.drop(columns=['maxtemp','mintemp','dewpoint'])

print(rainfall_data["rainfall"].value_counts())

rainfall_data.columns

df_major = rainfall_data[rainfall_data["rainfall"]==1]
df_minor = rainfall_data[rainfall_data["rainfall"]==0]

print(df_major.shape)
print(df_minor.shape)

df_major_ds = resample(df_major,replace=False,n_samples=len(df_minor),random_state=42)

df_major_ds.shape

df_ds = pd.concat([df_major_ds,df_minor])
df_ds.shape

df_ds.head()

df_ds["rainfall"].value_counts()

X = df_ds.drop(columns=["rainfall"])
y = df_ds["rainfall"]

X_train, X_test,y_train, y_test = train_test_split(X,y,test_size=0.2,random_state = 42)
rf_m = RandomForestClassifier(random_state=42)
param_grid_rf = {
    'n_estimators': [100, 200, 300],     # number of trees
    'max_depth': [None, 10, 20, 30],     # maximum depth of trees
    'min_samples_split': [2, 5, 10],     # minimum samples to split an internal node
    'min_samples_leaf': [1, 2, 4],       # minimum samples required at a leaf node
    'max_features':["sqrt","log2"]
}

# Perform grid search
grid_search = GridSearchCV(estimator=rf_m,
                           param_grid=param_grid_rf,
                           cv=5,
                           n_jobs=-1,
                           verbose=2)

# Fit the model
grid_search.fit(X_train, y_train)

best_rf_m = grid_search.best_estimator_
print(grid_search.best_params_)

cvs = cross_val_score(best_rf_m,X_train,y_train,cv=5)
print(cvs)
print(np.mean(cvs))

y_prediction = best_rf_m.predict(X_test)
print(confusion_matrix(y_test,y_prediction))
print(classification_report(y_test,y_prediction))
print(accuracy_score(y_test,y_prediction))

X.columns.tolist()

model = {
    "model": best_rf_m,
    "feature_names": X.columns.tolist()
}
with open("model.pkl","wb") as f:
  pickle.dump(model,f)

# using the model for prediction
import pickle
import pandas as pd
test = pd.read_csv("/content/test.csv")
test

test  = test.drop(columns=["maxtemp","mintemp","dewpoint","day"])

test

test.shape

ids= test['id']

with open('model.pkl', 'rb') as f:
    data = pickle.load(f)
    model = data['model']

X_test = test.drop(['id'], axis=1)

predictions = model.predict(test)

submission = pd.DataFrame({
    'id': test['id'],
    'rainfall': predictions
})

submission.to_csv('submission.csv', index=False)
print("✅ submission.csv created successfully")

train_data = pd.read_csv("/content/train.csv")

import pandas as pd
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import pickle

X = train_data.drop(columns=['rainfall', 'id'], errors='ignore')
y = train_data['rainfall']
X_train, X_val, y_train, y_val = train_test_split(
    X, y, test_size=0.2, random_state=42
)

xgb_model = xgb.XGBClassifier(
    n_estimators=500,
    learning_rate=0.05,
    max_depth=6,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    eval_metric='logloss'
)

xgb_model.fit(X_train, y_train)

y_pred = xgb_model.predict(X_val)
val_acc = accuracy_score(y_val, y_pred)
print(f"Validation Accuracy: {val_acc:.4f}")

# Load test data
test_df = pd.read_csv('test.csv')
X_test = test_df.drop(columns=['id'], errors='ignore')

# Predict rainfall
test_predictions = xgb_model.predict(X_test)

# Save submission
submission = pd.DataFrame({
    'id': test_df['id'],
    'rainfall': test_predictions
})
submission.to_csv('xgb_submission.csv', index=False)
print("✅ xgb_submission.csv created successfully!")

import matplotlib.pyplot as plt
xgb.plot_importance(xgb_model, importance_type='gain', max_num_features=10)
plt.title("Top 10 Important Features for Rainfall Prediction")
plt.show()